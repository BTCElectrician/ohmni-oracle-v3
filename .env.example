# =========================================
# AUTH
# =========================================
# OpenAI key (put the REAL key in .env, never commit it)
OPENAI_API_KEY=YOUR_OPENAI_API_KEY

# =========================================
# LOGGING / RUNTIME
# =========================================
LOG_LEVEL=INFO
PIPELINE_LOG_LEVEL=INFO
BATCH_SIZE=10                 # max parallel files
API_RATE_LIMIT=60             # per TIME_WINDOW
TIME_WINDOW=60                # seconds window for rate limit
MAX_CONCURRENT_API_CALLS=20   # per-process concurrency

# =========================================
# FEATURE TOGGLES
# =========================================
MECH_SECOND_PASS=false        # extra mechanical JSON pass
ENABLE_TABLE_EXTRACTION=false # PyMuPDF find_tables(); off = faster
ENABLE_AI_CACHE=false         # response cache off by default
AI_CACHE_TTL_HOURS=24
ENABLE_METADATA_REPAIR=true   # title-block metadata cleanup

# =========================================
# MODEL SELECTION (CURRENT: GPT-4.1 FAMILY)
# =========================================
DEFAULT_MODEL=gpt-4.1-mini    # fast default
LARGE_DOC_MODEL=gpt-4.1       # bigger model for long/complex docs
SCHEDULE_MODEL=gpt-4.1-mini   # schedules/specs
TINY_MODEL=gpt-4.1-nano       # optional tiny model (blank to disable)
TINY_MODEL_THRESHOLD=3000     # chars; use tiny below this

# Size thresholds (input characters) for model routing
NANO_CHAR_THRESHOLD=3000
MINI_CHAR_THRESHOLD=15000

# Force everything to the DEFAULT_MODEL (rare; usually leave false)
FORCE_MINI_MODEL=false

# =========================================
# TEMPERATURES & TOKEN LIMITS
# =========================================
DEFAULT_MODEL_TEMP=0.2
DEFAULT_MODEL_MAX_TOKENS=32768  # GPT-4.1 Mini output limit

LARGE_MODEL_TEMP=0.2
LARGE_MODEL_MAX_TOKENS=32768  # GPT-4.1 output limit

TINY_MODEL_TEMP=0.2
TINY_MODEL_MAX_TOKENS=32768  # GPT-4.1 Nano output limit

# Hard cap (provider limit) - All GPT-4.1 variants support 32,768 output tokens
# Context window: ~1 million tokens for all models
ACTUAL_MODEL_MAX_COMPLETION_TOKENS=32768

# Limit for specification docs (keeps outputs reasonable)
SPEC_MAX_TOKENS=16384

# Chat Completions API timeout (seconds)
RESPONSES_TIMEOUT_SECONDS=600

# =========================================
# OCR (scanned drawings)
# If OCR_ENABLED=true and chars/page < OCR_THRESHOLD, OCR up to OCR_MAX_PAGES.
# =========================================
OCR_ENABLED=true
OCR_THRESHOLD=1500    # chars per page threshold
OCR_MAX_PAGES=2       # cost control
OCR_MODEL=gpt-4o-mini
OCR_GRID_SIZE=1       # 1 = whole page (no tiling). Use 3 for 3x3.
OCR_DPI=300
OCR_TOKENS_PER_TILE=3000
